{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfrKNROhioFg"
   },
   "source": [
    "## SNU PPSML - Machine Learning Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIeqMK47xj1X"
   },
   "source": [
    "#### **Contents**\n",
    "---\n",
    "* ML exercise 1: Gradient Descent [Optimization @ ML] (HW05)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0PmZbFvxj_G"
   },
   "source": [
    "---\n",
    "* **ML exercise 2: Neural Network [Representation @ ML] (실습과제 11/5-8 & 11/9 강의)**\n",
    "    - 입력 속성데이터와 지도라벨값 $\\{(x_i, y_i)\\}$ @ 인코딩: 입력과 출력층의 설정  \n",
    "\n",
    "    - 순전파 신경망(def feedforward())의 구성을 위한 여러가지 파라메터들     \n",
    "        - $N_{layers}$ & $N_{nodes}$ in each layer\n",
    "        - 가중치와 편향치 ($W$ & $B$)\n",
    "        - 가중합(퍼셉트론 입력) : \n",
    "        \n",
    "        > $a_j=W_{ji} f_i(a_i)+B_j$ (전층의 출력 $f_i$에 대한 가중합)\n",
    "        \n",
    "        - 활성화 함수(출력) : $f_j(a_j)$\n",
    "        \n",
    "        > $f(a)=\\frac{1}{1+\\exp^{-a}}$ for sigmoid  \n",
    "        \n",
    "        > $f(a)=\\tanh(a)$ for tanh  \n",
    "        \n",
    "        > $f(a_k)=\\frac{\\exp[a_k]}{\\sum_{k'}\\exp[a_{k'}]}$ for softmax  \n",
    "        \n",
    "        > $f(a)=a$ for $ a > 0$ otherwise $0$ (ReLU)\n",
    "        \n",
    "        - 데이터의 순전파를 통한 최종 출력값 얻기: def feedforward(input)\n",
    "        - ...\n",
    "        \n",
    "    - 오차보정의 역전파:  \n",
    "    \n",
    "        - 지도라벨값의 인코딩과 오차함수($E(w;x)$)의 정의\n",
    "        - $\\delta_j$ (가중합 $a_j$에 대한 오차보정항 $\\equiv\\frac{\\partial E}{\\partial a_j}$)\n",
    "        - $\\delta_j$를 통한 가중치보정 역전파의 구현\n",
    "        - ...\n",
    "        \n",
    "    - 많은 데이터에 대한 학습 알고리즘 구현\n",
    "    - check a contour of MLP's probability output for classification of 2D data  \n",
    "    \n",
    "---   \n",
    "* ML exercise 3: Training a NN for Regression & Classification [Evaluation, Rep, Opt @ ML] (HW06)\n",
    "    - batch GD, mini-batch GD, stochastic GD  \n",
    "        - Visualize the minimizers in 2D\n",
    "    - Validation of model, Over-fitting, Bias & Variance  \n",
    "        - Visualize an over-fitted status\n",
    "    - Evaluation of model performance\n",
    "        - error(loss), accuracy (...)\n",
    "        - NN score & ROC(Receiver Operating Characteristic) curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7Ghj7f0ioFm"
   },
   "outputs": [],
   "source": [
    "# Printing all outputs in a cell (not only the last output)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DBgpcWDioHC"
   },
   "source": [
    "----\n",
    "### ** 2. Neural Netowrk Representation for ML ** \n",
    "\n",
    "### For Supervised Learning (Classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHT3Bwo9xm8U"
   },
   "source": [
    "---\n",
    "#### ** 1) [이종분류(Binary Classification)]** \n",
    "   \n",
    "   $x_1,\\,x_2$ 2차원 평면에 **두 종류**의 데이터가 분포해있을때, 임의의 $(x_1,x_2)$위치의 테스트 데이터가 각각의 종에 속할 확률을 예측하는, 이종 분류 신경망을 건설하고 훈련시켜보자.\n",
    "\n",
    "    - 훈련한 모형의 예측치를 matplotlib를 활용하여 시각화해보자.\n",
    "    - 각 epoch마다 성능을 평가하여 학습곡선을 그려보자.\n",
    "    - 여러가지 학습률값에 대하여 학습곡선의 차이를 시각화해보자\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UI_Mo5hxVH_"
   },
   "source": [
    "* 훈련 & 테스트 데이터의 로딩 그리고 시각화 \n",
    "- [[훈련데이터 폴더]](https://drive.google.com/open?id=1nhuCjcgovMkyy08FhTlqw_GTSei1FNNI) 에서 다운받은 data폴더를 본 노트북 폴더안에 위치시킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMRUBapbxVIC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_np_circles = np.load('data/2Classes_2d_circles.npy')\n",
    "data_np_moons = np.load('data/2Classes_2d_moons.npy')\n",
    "data_np_spirals = np.load('data/2Classes_2d_spirals.npy')\n",
    "\n",
    "\n",
    "print (len(data_np_circles))\n",
    "print (len(data_np_moons))\n",
    "print (len(data_np_spirals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UoQ19WF6Lt7"
   },
   "outputs": [],
   "source": [
    "# Check your data\n",
    "data = data_np_circles\n",
    "print (data.shape) \n",
    "# 각행(/10000행): 하나의 데이터 (10000개의 행 = 총 10000개의 데이터) \n",
    "# 각열(/3열): 각 데이터 하나하나가 가진 속성들, {1열: 데이터의 종류/클래스(정수형 인코딩, 0:빨간공, 1:파란공, ...etc), 2열: 데이터속성변수(x)값, 3열: 데이터속성변수(y)값}]\n",
    "print (data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEEtZ-e3xVIK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from itertools import cycle, islice\n",
    "%matplotlib inline\n",
    "\n",
    "data = data_np_circles\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "ax.scatter(data[:,1],data[:,2], c=data[:,0], cmap=cm, marker='.')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ER006kAc3Fgh"
   },
   "source": [
    "* NNfactory 모듈의 로딩과 MLP 인스턴스의 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwLWLfpHxVIS"
   },
   "outputs": [],
   "source": [
    "# (모듈로서) NNfactory.py의 로딩\n",
    "# autoreload 구문을 통해 \n",
    "# NNfactory.py에의 최신 수정 사항이 재import시마다 반영되도록 한다. \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# NNfactory.py 참조 \n",
    "import NNfactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2p-ZQk9xVIW"
   },
   "outputs": [],
   "source": [
    "# 완전연결순방향앞먹임 신경망 (fully connected feed-forward neural network, MLP) 구조의 설정\n",
    "model_str = '2:identity|'+2*'10:tanh|'+'2:softmax'\n",
    "# 학습률\n",
    "lr = 0.01\n",
    "# 모델이름\n",
    "name_tag = 'circle_lr'+str(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Af1nypdnxVIe"
   },
   "outputs": [],
   "source": [
    "# mynn이라는 이름의 신경망(MLP) 클래스 인스턴스를 선언.\n",
    "mynn = NNfactory.MLP(model_structure=model_str, \\\n",
    "                     model_nametag=name_tag, \\\n",
    "                     learning_rate=lr, \\\n",
    "                     encoding='one-hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q39vLl923WeB"
   },
   "source": [
    "* 로드한 데이터(2차원 속성변수공간에 분포한 2종의 데이터)들을 분류해내는 확률모형을, 갓 빚어낸 mynn신경망에 학습시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUlKiyYTxVIm"
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 준비\n",
    "data_type=None # = 'mnist' for MNIST-data, or None for others \n",
    "encoding='one-hot' #'integer' # 'float'\n",
    "training_data_list = data_np_circles # 학습에 쓸 데이터\n",
    "\n",
    "n_class = int(training_data_list[:,0].max()+1) # 분류모형에서의 클래스 갯수 추출\n",
    "dim_x = len(training_data_list[0])-1 # 데이터의 속성변수(x)의 차원 추출\n",
    "print(' * n_class = ',n_class)\n",
    "print(' * dim_x = ',dim_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fayhtaSKxVI0"
   },
   "outputs": [],
   "source": [
    "# 최대 학습 주기 설정\n",
    "epochs = 100\n",
    "\n",
    "n_data_tot=len(training_data_list)\n",
    "n_data_max=5000  # 훈련에 사용할 데이터 갯수\n",
    "n_data_test=min(int((n_data_tot-n_data_max)*0.5),int(n_data_max*0.5))\n",
    "n_data = len(training_data_list[:n_data_max])\n",
    "dn_data = int(n_data/20)\n",
    "print (dn_data)\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all data in the training data set\n",
    "    print(' * epoch = {}'.format(e+1))\n",
    "    id_data = 0\n",
    "    \n",
    "    for data in training_data_list[:n_data_max]:\n",
    "        \n",
    "        # 프로세스 게이지\n",
    "        id_data += 1\n",
    "        if (id_data%dn_data==0):\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.write(' [%-20s] %d%%' % ( '='*(id_data//dn_data), 5*(id_data//dn_data)))\n",
    "            sys.stdout.flush()\n",
    "            sleep(0.25)\n",
    "        \n",
    "        # 입력/지도 데이터 가공 \n",
    "        if data_type == 'mnist':\n",
    "            # split the mnist data by the ',' commas\n",
    "            all_values = data.split(',')\n",
    "            # 입력 데이터 스케일링 \n",
    "            input_list = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "            # 지도 라벨 벡터 가공 (shape = (10,))\n",
    "            target_list = np.zeros(10) #mynn.n_nodes[-1])\n",
    "            # all_values[0] is the target label for this data\n",
    "            target_list[int(all_values[0])] = 1.0\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            input_list = data[1:] #np.asfarray(all_values[1:])        \n",
    "            target_origin = data[0]\n",
    "            \n",
    "            if encoding == 'one-hot':\n",
    "\n",
    "                target_list = np.zeros(mynn.n_nodes[-1])\n",
    "                target_list[int(data[0])] = 1\n",
    "    \n",
    "            elif encoding == 'integer':\n",
    "                \n",
    "                target_list = np.zeros(1)\n",
    "                target_list[0] = int(data[0])\n",
    "\n",
    "            elif encoding == 'float':\n",
    "                \n",
    "                target_list = np.zeros(1)\n",
    "                target_list[0] = data[0]\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(' => check your encoding scheme. ')\n",
    "\n",
    "        \n",
    "        mynn.train(input_list, target_list)\n",
    "\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    print('')\n",
    "    print(' > 훈련 샘플에 대한 성능 (정확도 & 평균에러) ')\n",
    "    mynn.check_accuracy_error(training_data_list, 0, n_data_max, data_type=None)\n",
    "    print('')\n",
    "    print(' > 테스트 샘플에 대한 성능 (정확도 & 평균에러) ')\n",
    "    mynn.check_accuracy_error(training_data_list, n_data_max, n_data_max + n_data_test, data_type=None)\n",
    "        \n",
    "    print('\\n')\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXVquXY4xVI9"
   },
   "source": [
    "---\n",
    "* 훈련한 모형의 저장\n",
    "\n",
    "훈련된 모형은 NNfactory클래스 안의 save_model메소드를 사용하여 .npy포맷의 numpy array로 저장할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkpqVG_ZxVI_"
   },
   "outputs": [],
   "source": [
    "mynn.save_model(fname='mlp_circle_2tanh.npy', nametag='circle_2tanh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sASjw8pxxVJD"
   },
   "source": [
    "---\n",
    "* 저장된 모형 불러오기 :\n",
    "\n",
    "저장된 .npy파일로부터 신경망정보가 담긴 넘파이 배열을 직접 로드하고, 이 넘파이 배열을 새 신경망 인스턴스 생성에 사용하여 저장된 모형과 똑같은 신경망을 로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6iONXCexVJF"
   },
   "outputs": [],
   "source": [
    "mynn_npy = np.load('mlp_circle_2tanh.npy')\n",
    "mynn_load = NNfactory.MLP(load_model_np=mynn_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0TGq4mAkxVJO"
   },
   "source": [
    "---\n",
    "* 학습한 확률 모형을 시각화해보기 (확률모형의 출력을 2d에 contour plot해보자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elJ9ox_0xVJP"
   },
   "outputs": [],
   "source": [
    "# event 하나에 대한 출력값 테스트\n",
    "data = data_np_circles\n",
    "\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "print(data[0,:])\n",
    "print(mynn_load.feedforward(data[0,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYZUUT12xVJV"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ==================================== #\n",
    "# * Plotting model prediction contour \n",
    "# ==================================== #\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from itertools import cycle, islice\n",
    "\n",
    "\n",
    "# 데이터 로드 & 저장파일이름설정\n",
    "data = data_np_circles\n",
    "savefigfile = 'prediction_model_given_circle_data.png'\n",
    "\n",
    "\n",
    "# 등고선 플랏을 위한 그리드 설정\n",
    "x_min, x_max = data[:,1].min(), data[:,1].max()\n",
    "y_min, y_max = data[:,2].min(), data[:,2].max()\n",
    "n_x = 100\n",
    "n_y = 100\n",
    "x = np.linspace(x_min, x_max, n_x)\n",
    "y = np.linspace(y_min, y_max, n_y)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# 각 (X[j,i],Y[j,i]) 위치에서의 신경망 출력(~첫번째 클래스일 확률)을 담을 배열 설정\n",
    "P = np.zeros(n_x*n_y).reshape(n_y,n_x)\n",
    "\n",
    "for j in range(n_y):\n",
    "    for i in range(n_x):    \n",
    "        P[j,i] = mynn_load.feedforward([X[j,i],Y[j,i]])[0]\n",
    "    \n",
    "print('x_mesh.shape  = ',X.shape)\n",
    "print('y_mesh.shape  = ',Y.shape)\n",
    "print('P_mesh.shape  = ',P.shape)\n",
    "\n",
    "\n",
    "# 신경망이 학습한 확률모형의 등고선을 데이터와 함께 시각화\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#0000FF', '#FF0000'])\n",
    "\n",
    "ax.contourf(X, Y, P, cmap=cm, alpha=.8)\n",
    "ax.scatter(data[:,1],data[:,2], c=data[:,0], cmap=cm_bright, alpha=0.8, marker='.')\n",
    "\n",
    "ax.grid(True)\n",
    "fig.savefig(savefigfile)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4LIfsWAxVJb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io4LHri1y66B"
   },
   "source": [
    "---\n",
    "#### ** 2) [회귀(Regressions)]** 1D data $x$ with continous label $y$, $x\\rightarrow y(x)$\n",
    "\n",
    "   - 회귀모형에서는 출력층의 활성화함수를 항등원 $f(a)=a$를 사용한다. 이에 맞도록 역전파식이 적절히 수정된 신경망 클래스를 작성해보고, 훈련시켜보자.  \n",
    "   - 훈련한 모형의 예측치를 matplotlib를 활용하여 시각화해보자.\n",
    "   - 각 epoch마다 성능을 평가하여 학습곡선을 그려보자. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLH90Tq-xVJj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 2-1,2-2) Data generation\n",
    "\n",
    "T = np.random.uniform(0,2,1000)\n",
    "# T.sort()\n",
    "\n",
    "# model\n",
    "a = 1.\n",
    "b = 0.\n",
    "X = a*np.sin(2*np.pi*T) + b\n",
    "# noise \n",
    "dX = (X/10) * np.random.randn(len(X))\n",
    "# experimental value = model + noise\n",
    "X_exp = X  + dX\n",
    "\n",
    "\n",
    "# 2-3) Plotting\n",
    "\n",
    "## plot objects (figure & axes)\n",
    "fig1 = plt.figure(figsize=(12,8))\n",
    "ax1 = fig1.add_subplot(111)\n",
    "\n",
    "ax1.plot(T, X_exp, 'g.')\n",
    "ax1.set_xlabel('time (s)', fontsize=20)\n",
    "ax1.set_ylabel('spring ocillation, $x(t)$', fontsize=20)\n",
    "ax1.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "snu_ppsml_note_07_ml_exercise.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
